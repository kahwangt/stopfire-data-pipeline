# stopfire data pipeline
 Data pipeline using Apache Kafka, Apache Spark Streaming and MongoDB

In conjunction with assessment of FIT5148 - Distributed Databases and Big Data where one is required to build an application that includes a data pipeline from streaming to storing, and analysing the data using Apache Kafka, Apache Spark Streaming and MongoDB.

Stimulated real-time data using 3 Apache Kafka producers that loads data from 3 different datasets and randomly feed to the data stream for every time interval

Built a streaming application in Apache Spark Streaming that received that the data from Apache Kafka producers and transformed the data accordingly for visualisation

Performed data visualisation using Python matplotlib on streaming and static data

Scored a High Distinction for the successful seamless implementation of the data pipeline that included Extract, Transform and Load (ETL)
